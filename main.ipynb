{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main(3).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6j5KhLs1Vug","executionInfo":{"status":"ok","timestamp":1621287073352,"user_tz":-240,"elapsed":49196,"user":{"displayName":"Vibha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEio_ZhZQPIAbRsxl7zbUbuJPoau_muMk78br7Lw=s64","userId":"04955807991990669110"}},"outputId":"53ea3609-c666-404f-b531-d811dcf876d7"},"source":["# !pip install SimpleITK      \n","# !pip install medpy          # Required for preprocessing\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DEav34JB1ZqI","executionInfo":{"status":"ok","timestamp":1621287081308,"user_tz":-240,"elapsed":12086,"user":{"displayName":"Vibha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEio_ZhZQPIAbRsxl7zbUbuJPoau_muMk78br7Lw=s64","userId":"04955807991990669110"}}},"source":["import numpy as np # linear algebra\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import tensorflow as tf\n","from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.optim import lr_scheduler\n","from tensorflow import keras\n","from skimage.io import imsave\n","from keras.models import Model\n","from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n","from keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","from torch.nn import functional as F\n","from collections import defaultdict\n","from sklearn.model_selection import KFold\n","writer = SummaryWriter(\"runs/new\")\n","\n","torch.manual_seed(7)\n","\n","import os\n","# os._exit(00)\n","os.chdir('drive/MyDrive/CAMUS_DATASET/WEIGHTS/Stuff/src')\n","from preprocessing import*\n","from model import*\n","from dataset import *\n","from train import *\n","from loss import*\n","os.chdir('../../')\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucRPXHNw2F0m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620545584392,"user_tz":-240,"elapsed":7946,"user":{"displayName":"vishal ramesh","photoUrl":"","userId":"12257699543990293148"}},"outputId":"0dc4c344-3139-4574-dd6c-c1bf23f8cfc2"},"source":["image = torch.rand((4,1,128,128))\n","image.to(device='cuda')\n","model = ResUnetPlusPlus_Path(16)\n","print(model(image).shape)\n","summary(model.cuda(), (1,128,128))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([4, 4, 128, 128])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 16, 128, 128]             160\n","       BatchNorm2d-2         [-1, 16, 128, 128]              32\n","              ReLU-3         [-1, 16, 128, 128]               0\n","            Conv2d-4         [-1, 16, 128, 128]           2,320\n","            Conv2d-5         [-1, 16, 128, 128]             160\n"," AdaptiveAvgPool2d-6             [-1, 16, 1, 1]               0\n","            Linear-7                    [-1, 1]              16\n","              ReLU-8                    [-1, 1]               0\n","            Linear-9                   [-1, 16]              16\n","          Sigmoid-10                   [-1, 16]               0\n","Squeeze_Excite_Block-11         [-1, 16, 128, 128]               0\n","      BatchNorm2d-12         [-1, 16, 128, 128]              32\n","             ReLU-13         [-1, 16, 128, 128]               0\n","           Conv2d-14           [-1, 32, 64, 64]           4,640\n","      BatchNorm2d-15           [-1, 32, 64, 64]              64\n","             ReLU-16           [-1, 32, 64, 64]               0\n","           Conv2d-17           [-1, 32, 64, 64]           9,248\n","           Conv2d-18           [-1, 32, 64, 64]           4,640\n","      BatchNorm2d-19           [-1, 32, 64, 64]              64\n","     ResidualConv-20           [-1, 32, 64, 64]               0\n","           Conv2d-21         [-1, 16, 128, 128]             272\n","           Conv2d-22           [-1, 16, 42, 42]           2,320\n","             ReLU-23         [-1, 16, 128, 128]               0\n","      BatchNorm2d-24         [-1, 16, 128, 128]              32\n","          ResPath-25         [-1, 16, 128, 128]               0\n","           Conv2d-26         [-1, 16, 128, 128]             272\n","           Conv2d-27           [-1, 16, 42, 42]           2,320\n","             ReLU-28         [-1, 16, 128, 128]               0\n","      BatchNorm2d-29         [-1, 16, 128, 128]              32\n","          ResPath-30         [-1, 16, 128, 128]               0\n","           Conv2d-31         [-1, 16, 128, 128]             272\n","           Conv2d-32           [-1, 16, 42, 42]           2,320\n","             ReLU-33         [-1, 16, 128, 128]               0\n","      BatchNorm2d-34         [-1, 16, 128, 128]              32\n","          ResPath-35         [-1, 16, 128, 128]               0\n","           Conv2d-36         [-1, 16, 128, 128]             272\n","           Conv2d-37           [-1, 16, 42, 42]           2,320\n","             ReLU-38         [-1, 16, 128, 128]               0\n","      BatchNorm2d-39         [-1, 16, 128, 128]              32\n","          ResPath-40         [-1, 16, 128, 128]               0\n","AdaptiveAvgPool2d-41             [-1, 32, 1, 1]               0\n","           Linear-42                    [-1, 2]              64\n","             ReLU-43                    [-1, 2]               0\n","           Linear-44                   [-1, 32]              64\n","          Sigmoid-45                   [-1, 32]               0\n","Squeeze_Excite_Block-46           [-1, 32, 64, 64]               0\n","      BatchNorm2d-47           [-1, 32, 64, 64]              64\n","             ReLU-48           [-1, 32, 64, 64]               0\n","           Conv2d-49           [-1, 64, 32, 32]          18,496\n","      BatchNorm2d-50           [-1, 64, 32, 32]             128\n","             ReLU-51           [-1, 64, 32, 32]               0\n","           Conv2d-52           [-1, 64, 32, 32]          36,928\n","           Conv2d-53           [-1, 64, 32, 32]          18,496\n","      BatchNorm2d-54           [-1, 64, 32, 32]             128\n","     ResidualConv-55           [-1, 64, 32, 32]               0\n","           Conv2d-56           [-1, 32, 64, 64]           1,056\n","           Conv2d-57           [-1, 32, 21, 21]           9,248\n","             ReLU-58           [-1, 32, 64, 64]               0\n","      BatchNorm2d-59           [-1, 32, 64, 64]              64\n","          ResPath-60           [-1, 32, 64, 64]               0\n","           Conv2d-61           [-1, 32, 64, 64]           1,056\n","           Conv2d-62           [-1, 32, 21, 21]           9,248\n","             ReLU-63           [-1, 32, 64, 64]               0\n","      BatchNorm2d-64           [-1, 32, 64, 64]              64\n","          ResPath-65           [-1, 32, 64, 64]               0\n","           Conv2d-66           [-1, 32, 64, 64]           1,056\n","           Conv2d-67           [-1, 32, 21, 21]           9,248\n","             ReLU-68           [-1, 32, 64, 64]               0\n","      BatchNorm2d-69           [-1, 32, 64, 64]              64\n","          ResPath-70           [-1, 32, 64, 64]               0\n","AdaptiveAvgPool2d-71             [-1, 64, 1, 1]               0\n","           Linear-72                    [-1, 4]             256\n","             ReLU-73                    [-1, 4]               0\n","           Linear-74                   [-1, 64]             256\n","          Sigmoid-75                   [-1, 64]               0\n","Squeeze_Excite_Block-76           [-1, 64, 32, 32]               0\n","      BatchNorm2d-77           [-1, 64, 32, 32]             128\n","             ReLU-78           [-1, 64, 32, 32]               0\n","           Conv2d-79          [-1, 128, 16, 16]          73,856\n","      BatchNorm2d-80          [-1, 128, 16, 16]             256\n","             ReLU-81          [-1, 128, 16, 16]               0\n","           Conv2d-82          [-1, 128, 16, 16]         147,584\n","           Conv2d-83          [-1, 128, 16, 16]          73,856\n","      BatchNorm2d-84          [-1, 128, 16, 16]             256\n","     ResidualConv-85          [-1, 128, 16, 16]               0\n","           Conv2d-86           [-1, 64, 32, 32]           4,160\n","           Conv2d-87           [-1, 64, 10, 10]          36,928\n","             ReLU-88           [-1, 64, 32, 32]               0\n","      BatchNorm2d-89           [-1, 64, 32, 32]             128\n","          ResPath-90           [-1, 64, 32, 32]               0\n","           Conv2d-91           [-1, 64, 32, 32]           4,160\n","           Conv2d-92           [-1, 64, 10, 10]          36,928\n","             ReLU-93           [-1, 64, 32, 32]               0\n","      BatchNorm2d-94           [-1, 64, 32, 32]             128\n","          ResPath-95           [-1, 64, 32, 32]               0\n","           Conv2d-96          [-1, 256, 16, 16]         295,168\n","             ReLU-97          [-1, 256, 16, 16]               0\n","      BatchNorm2d-98          [-1, 256, 16, 16]             512\n","           Conv2d-99          [-1, 256, 16, 16]         295,168\n","            ReLU-100          [-1, 256, 16, 16]               0\n","     BatchNorm2d-101          [-1, 256, 16, 16]             512\n","          Conv2d-102          [-1, 256, 16, 16]         295,168\n","            ReLU-103          [-1, 256, 16, 16]               0\n","     BatchNorm2d-104          [-1, 256, 16, 16]             512\n","          Conv2d-105          [-1, 256, 16, 16]         196,864\n","            ASPP-106          [-1, 256, 16, 16]               0\n","     BatchNorm2d-107           [-1, 64, 32, 32]             128\n","            ReLU-108           [-1, 64, 32, 32]               0\n","          Conv2d-109          [-1, 256, 32, 32]         147,712\n","       MaxPool2d-110          [-1, 256, 16, 16]               0\n","     BatchNorm2d-111          [-1, 256, 16, 16]             512\n","            ReLU-112          [-1, 256, 16, 16]               0\n","          Conv2d-113          [-1, 256, 16, 16]         590,080\n","     BatchNorm2d-114          [-1, 256, 16, 16]             512\n","            ReLU-115          [-1, 256, 16, 16]               0\n","          Conv2d-116            [-1, 1, 16, 16]             257\n","  AttentionBlock-117          [-1, 256, 16, 16]               0\n","        Upsample-118          [-1, 256, 32, 32]               0\n","       Upsample_-119          [-1, 256, 32, 32]               0\n","     BatchNorm2d-120          [-1, 320, 32, 32]             640\n","            ReLU-121          [-1, 320, 32, 32]               0\n","          Conv2d-122          [-1, 128, 32, 32]         368,768\n","     BatchNorm2d-123          [-1, 128, 32, 32]             256\n","            ReLU-124          [-1, 128, 32, 32]               0\n","          Conv2d-125          [-1, 128, 32, 32]         147,584\n","          Conv2d-126          [-1, 128, 32, 32]         368,768\n","     BatchNorm2d-127          [-1, 128, 32, 32]             256\n","    ResidualConv-128          [-1, 128, 32, 32]               0\n","     BatchNorm2d-129           [-1, 32, 64, 64]              64\n","            ReLU-130           [-1, 32, 64, 64]               0\n","          Conv2d-131          [-1, 128, 64, 64]          36,992\n","       MaxPool2d-132          [-1, 128, 32, 32]               0\n","     BatchNorm2d-133          [-1, 128, 32, 32]             256\n","            ReLU-134          [-1, 128, 32, 32]               0\n","          Conv2d-135          [-1, 128, 32, 32]         147,584\n","     BatchNorm2d-136          [-1, 128, 32, 32]             256\n","            ReLU-137          [-1, 128, 32, 32]               0\n","          Conv2d-138            [-1, 1, 32, 32]             129\n","  AttentionBlock-139          [-1, 128, 32, 32]               0\n","        Upsample-140          [-1, 128, 64, 64]               0\n","       Upsample_-141          [-1, 128, 64, 64]               0\n","     BatchNorm2d-142          [-1, 160, 64, 64]             320\n","            ReLU-143          [-1, 160, 64, 64]               0\n","          Conv2d-144           [-1, 64, 64, 64]          92,224\n","     BatchNorm2d-145           [-1, 64, 64, 64]             128\n","            ReLU-146           [-1, 64, 64, 64]               0\n","          Conv2d-147           [-1, 64, 64, 64]          36,928\n","          Conv2d-148           [-1, 64, 64, 64]          92,224\n","     BatchNorm2d-149           [-1, 64, 64, 64]             128\n","    ResidualConv-150           [-1, 64, 64, 64]               0\n","     BatchNorm2d-151         [-1, 16, 128, 128]              32\n","            ReLU-152         [-1, 16, 128, 128]               0\n","          Conv2d-153         [-1, 64, 128, 128]           9,280\n","       MaxPool2d-154           [-1, 64, 64, 64]               0\n","     BatchNorm2d-155           [-1, 64, 64, 64]             128\n","            ReLU-156           [-1, 64, 64, 64]               0\n","          Conv2d-157           [-1, 64, 64, 64]          36,928\n","     BatchNorm2d-158           [-1, 64, 64, 64]             128\n","            ReLU-159           [-1, 64, 64, 64]               0\n","          Conv2d-160            [-1, 1, 64, 64]              65\n","  AttentionBlock-161           [-1, 64, 64, 64]               0\n","        Upsample-162         [-1, 64, 128, 128]               0\n","       Upsample_-163         [-1, 64, 128, 128]               0\n","     BatchNorm2d-164         [-1, 80, 128, 128]             160\n","            ReLU-165         [-1, 80, 128, 128]               0\n","          Conv2d-166         [-1, 32, 128, 128]          23,072\n","     BatchNorm2d-167         [-1, 32, 128, 128]              64\n","            ReLU-168         [-1, 32, 128, 128]               0\n","          Conv2d-169         [-1, 32, 128, 128]           9,248\n","          Conv2d-170         [-1, 32, 128, 128]          23,072\n","     BatchNorm2d-171         [-1, 32, 128, 128]              64\n","    ResidualConv-172         [-1, 32, 128, 128]               0\n","          Conv2d-173         [-1, 16, 128, 128]           4,624\n","            ReLU-174         [-1, 16, 128, 128]               0\n","     BatchNorm2d-175         [-1, 16, 128, 128]              32\n","          Conv2d-176         [-1, 16, 128, 128]           4,624\n","            ReLU-177         [-1, 16, 128, 128]               0\n","     BatchNorm2d-178         [-1, 16, 128, 128]              32\n","          Conv2d-179         [-1, 16, 128, 128]           4,624\n","            ReLU-180         [-1, 16, 128, 128]               0\n","     BatchNorm2d-181         [-1, 16, 128, 128]              32\n","          Conv2d-182         [-1, 16, 128, 128]             784\n","            ASPP-183         [-1, 16, 128, 128]               0\n","          Conv2d-184          [-1, 4, 128, 128]              68\n","================================================================\n","Total params: 3,749,911\n","Trainable params: 3,749,911\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.06\n","Forward/backward pass size (MB): 267.58\n","Params size (MB): 14.30\n","Estimated Total Size (MB): 281.94\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X8UUV3OK1qA9","executionInfo":{"status":"ok","timestamp":1621287091704,"user_tz":-240,"elapsed":17295,"user":{"displayName":"Vibha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEio_ZhZQPIAbRsxl7zbUbuJPoau_muMk78br7Lw=s64","userId":"04955807991990669110"}}},"source":["train_ED_np = (np.load('ED_train_cv2.npy')).reshape((900,1,256,256))\n","train_ED_gt_np = (np.load('ED_train_gt_cv2.npy')).reshape((900,1,256,256)).astype(int)\n","train_ES_np = (np.load('ES_train_cv2.npy')).reshape(900,1,256,256)\n","train_ES_gt_np = (np.load('ES_train_gt_cv2.npy')).reshape((900,1,256,256)).astype(int)\n","\n","train_ED_np = np.concatenate((train_ED_np, train_ES_np), axis=0)\n","train_ED_gt_np = np.concatenate((train_ED_gt_np, train_ES_gt_np), axis=0)\n","\n","data_train, data_test, mask_train, mask_test = train_test_split(train_ED_np, train_ED_gt_np, test_size=0.20, random_state=42)\n","batch_size = 16\n","train_dataset = SEMDataTrain(data_train, mask_train)\n","val_dataset = SEMDataTrain(data_test, mask_test)\n","\n","dataloader = {\n","    'train': torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n","    'val': torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","}\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FW_AMCzF2DQU","executionInfo":{"status":"ok","timestamp":1621289496938,"user_tz":-240,"elapsed":2395931,"user":{"displayName":"Vibha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEio_ZhZQPIAbRsxl7zbUbuJPoau_muMk78br7Lw=s64","userId":"04955807991990669110"}},"outputId":"81d2a667-28e2-4715-a1fd-311e206d00aa"},"source":["model = Unet(start_fm = 16)\n","model.cuda();\n","\n","criterion = nn.CrossEntropyLoss()\n","# criterion = SoftDiceLoss()\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n","\n","model = train(model,dataloader, criterion, learning_rate, optimizer, 100)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch 0/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.748576, dice: 0.649276, iou: 0.762148\n","BEGIN EVAL\n","val: criterion_loss: 0.472612, dice: 0.542377, iou: 0.669645\n","saving best model\n","0m 23s\n","Epoch 1/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.340409, dice: 0.446281, iou: 0.584161\n","BEGIN EVAL\n","val: criterion_loss: 0.263678, dice: 0.369914, iou: 0.513143\n","saving best model\n","0m 24s\n","Epoch 2/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.216823, dice: 0.301450, iou: 0.442630\n","BEGIN EVAL\n","val: criterion_loss: 0.211755, dice: 0.282593, iou: 0.421296\n","saving best model\n","0m 24s\n","Epoch 3/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.170678, dice: 0.232537, iou: 0.362458\n","BEGIN EVAL\n","val: criterion_loss: 0.160154, dice: 0.217213, iou: 0.343038\n","saving best model\n","0m 24s\n","Epoch 4/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.145681, dice: 0.195966, iou: 0.315779\n","BEGIN EVAL\n","val: criterion_loss: 0.149388, dice: 0.197851, iou: 0.318201\n","saving best model\n","0m 24s\n","Epoch 5/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.133416, dice: 0.176325, iou: 0.289242\n","BEGIN EVAL\n","val: criterion_loss: 0.148316, dice: 0.186998, iou: 0.303294\n","saving best model\n","0m 24s\n","Epoch 6/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.125197, dice: 0.164973, iou: 0.273419\n","BEGIN EVAL\n","val: criterion_loss: 0.131762, dice: 0.170200, iou: 0.280518\n","saving best model\n","0m 24s\n","Epoch 7/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.119174, dice: 0.155376, iou: 0.259886\n","BEGIN EVAL\n","val: criterion_loss: 0.135252, dice: 0.162587, iou: 0.268544\n","saving best model\n","0m 24s\n","Epoch 8/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.114491, dice: 0.149283, iou: 0.251146\n","BEGIN EVAL\n","val: criterion_loss: 0.118860, dice: 0.152427, iou: 0.255206\n","saving best model\n","0m 24s\n","Epoch 9/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.108309, dice: 0.141005, iou: 0.239104\n","BEGIN EVAL\n","val: criterion_loss: 0.115056, dice: 0.143656, iou: 0.243009\n","saving best model\n","0m 24s\n","Epoch 10/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.105499, dice: 0.136781, iou: 0.232980\n","BEGIN EVAL\n","val: criterion_loss: 0.117668, dice: 0.143277, iou: 0.242472\n","saving best model\n","0m 24s\n","Epoch 11/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.104276, dice: 0.134173, iou: 0.229077\n","BEGIN EVAL\n","val: criterion_loss: 0.129834, dice: 0.151844, iou: 0.253699\n","0m 24s\n","Epoch 12/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.100747, dice: 0.130647, iou: 0.223837\n","BEGIN EVAL\n","val: criterion_loss: 0.110977, dice: 0.139310, iou: 0.235857\n","saving best model\n","0m 24s\n","Epoch 13/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.094189, dice: 0.122565, iou: 0.211820\n","BEGIN EVAL\n","val: criterion_loss: 0.114674, dice: 0.136707, iou: 0.232756\n","saving best model\n","0m 24s\n","Epoch 14/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.098168, dice: 0.125504, iou: 0.216069\n","BEGIN EVAL\n","val: criterion_loss: 0.110540, dice: 0.139299, iou: 0.236247\n","0m 24s\n","Epoch 15/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.094931, dice: 0.122176, iou: 0.211128\n","BEGIN EVAL\n","val: criterion_loss: 0.100126, dice: 0.126677, iou: 0.217831\n","saving best model\n","0m 24s\n","Epoch 16/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.089489, dice: 0.115924, iou: 0.201746\n","BEGIN EVAL\n","val: criterion_loss: 0.119747, dice: 0.142080, iou: 0.239809\n","0m 24s\n","Epoch 17/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.088471, dice: 0.114424, iou: 0.199377\n","BEGIN EVAL\n","val: criterion_loss: 0.101023, dice: 0.122366, iou: 0.210976\n","saving best model\n","0m 24s\n","Epoch 18/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.085796, dice: 0.111163, iou: 0.194408\n","BEGIN EVAL\n","val: criterion_loss: 0.107714, dice: 0.128951, iou: 0.221024\n","0m 24s\n","Epoch 19/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.083734, dice: 0.108695, iou: 0.190541\n","BEGIN EVAL\n","val: criterion_loss: 0.100479, dice: 0.120862, iou: 0.208624\n","saving best model\n","0m 24s\n","Epoch 20/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.081301, dice: 0.104943, iou: 0.184716\n","BEGIN EVAL\n","val: criterion_loss: 0.099463, dice: 0.116506, iou: 0.202079\n","saving best model\n","0m 24s\n","Epoch 21/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.079813, dice: 0.103816, iou: 0.183006\n","BEGIN EVAL\n","val: criterion_loss: 0.106957, dice: 0.120991, iou: 0.209025\n","0m 24s\n","Epoch 22/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.080730, dice: 0.104323, iou: 0.183767\n","BEGIN EVAL\n","val: criterion_loss: 0.097380, dice: 0.116675, iou: 0.202514\n","0m 24s\n","Epoch 23/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.077597, dice: 0.100540, iou: 0.177814\n","BEGIN EVAL\n","val: criterion_loss: 0.103763, dice: 0.118591, iou: 0.205245\n","0m 24s\n","Epoch 24/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.075734, dice: 0.098145, iou: 0.174031\n","BEGIN EVAL\n","val: criterion_loss: 0.099698, dice: 0.113503, iou: 0.197838\n","saving best model\n","0m 24s\n","Epoch 25/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.075083, dice: 0.097040, iou: 0.172297\n","BEGIN EVAL\n","val: criterion_loss: 0.102267, dice: 0.113579, iou: 0.197710\n","0m 24s\n","Epoch 26/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.077181, dice: 0.099643, iou: 0.176433\n","BEGIN EVAL\n","val: criterion_loss: 0.105765, dice: 0.120874, iou: 0.208976\n","0m 24s\n","Epoch 27/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.072739, dice: 0.094518, iou: 0.168276\n","BEGIN EVAL\n","val: criterion_loss: 0.099280, dice: 0.113501, iou: 0.197695\n","saving best model\n","0m 24s\n","Epoch 28/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.071582, dice: 0.092577, iou: 0.165170\n","BEGIN EVAL\n","val: criterion_loss: 0.100964, dice: 0.111860, iou: 0.195347\n","saving best model\n","0m 24s\n","Epoch 29/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.070397, dice: 0.091588, iou: 0.163607\n","BEGIN EVAL\n","val: criterion_loss: 0.099254, dice: 0.110040, iou: 0.192636\n","saving best model\n","0m 24s\n","Epoch 30/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.068611, dice: 0.089087, iou: 0.159595\n","BEGIN EVAL\n","val: criterion_loss: 0.104468, dice: 0.113889, iou: 0.198002\n","0m 24s\n","Epoch 31/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.068044, dice: 0.088748, iou: 0.159072\n","BEGIN EVAL\n","val: criterion_loss: 0.098102, dice: 0.107112, iou: 0.187791\n","saving best model\n","0m 24s\n","Epoch 32/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.067809, dice: 0.087890, iou: 0.157656\n","BEGIN EVAL\n","val: criterion_loss: 0.101199, dice: 0.108256, iou: 0.189700\n","0m 24s\n","Epoch 33/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.065945, dice: 0.085349, iou: 0.153518\n","BEGIN EVAL\n","val: criterion_loss: 0.098321, dice: 0.108619, iou: 0.190247\n","0m 24s\n","Epoch 34/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.064395, dice: 0.083643, iou: 0.150752\n","BEGIN EVAL\n","val: criterion_loss: 0.103395, dice: 0.109552, iou: 0.191604\n","0m 24s\n","Epoch 35/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.066612, dice: 0.086410, iou: 0.155286\n","BEGIN EVAL\n","val: criterion_loss: 0.111966, dice: 0.116037, iou: 0.201538\n","0m 24s\n","Epoch 36/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.065176, dice: 0.085020, iou: 0.153047\n","BEGIN EVAL\n","val: criterion_loss: 0.097839, dice: 0.105270, iou: 0.184714\n","saving best model\n","0m 24s\n","Epoch 37/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.061671, dice: 0.080512, iou: 0.145704\n","BEGIN EVAL\n","val: criterion_loss: 0.104921, dice: 0.109023, iou: 0.191268\n","0m 24s\n","Epoch 38/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.059115, dice: 0.077053, iou: 0.139962\n","BEGIN EVAL\n","val: criterion_loss: 0.104602, dice: 0.105742, iou: 0.185778\n","0m 24s\n","Epoch 39/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.058062, dice: 0.075960, iou: 0.138163\n","BEGIN EVAL\n","val: criterion_loss: 0.106517, dice: 0.106870, iou: 0.187220\n","0m 24s\n","Epoch 40/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.058070, dice: 0.075746, iou: 0.137790\n","BEGIN EVAL\n","val: criterion_loss: 0.100001, dice: 0.098872, iou: 0.175017\n","saving best model\n","0m 24s\n","Epoch 41/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.058393, dice: 0.076260, iou: 0.138644\n","BEGIN EVAL\n","val: criterion_loss: 0.102838, dice: 0.102871, iou: 0.181189\n","0m 24s\n","Epoch 42/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.056701, dice: 0.073919, iou: 0.134767\n","BEGIN EVAL\n","val: criterion_loss: 0.099958, dice: 0.101502, iou: 0.179174\n","0m 24s\n","Epoch 43/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.055073, dice: 0.072092, iou: 0.131696\n","BEGIN EVAL\n","val: criterion_loss: 0.111011, dice: 0.104938, iou: 0.184329\n","0m 24s\n","Epoch 44/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.054928, dice: 0.071891, iou: 0.131389\n","BEGIN EVAL\n","val: criterion_loss: 0.107492, dice: 0.101146, iou: 0.178580\n","0m 24s\n","Epoch 45/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.053987, dice: 0.070345, iou: 0.128796\n","BEGIN EVAL\n","val: criterion_loss: 0.100879, dice: 0.100472, iou: 0.177697\n","0m 24s\n","Epoch 46/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.052765, dice: 0.069136, iou: 0.126789\n","BEGIN EVAL\n","val: criterion_loss: 0.104453, dice: 0.101393, iou: 0.178911\n","0m 24s\n","Epoch 47/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.050380, dice: 0.066154, iou: 0.121724\n","BEGIN EVAL\n","val: criterion_loss: 0.110961, dice: 0.102874, iou: 0.181483\n","0m 24s\n","Epoch 48/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.049873, dice: 0.065336, iou: 0.120306\n","BEGIN EVAL\n","val: criterion_loss: 0.104949, dice: 0.096517, iou: 0.171401\n","saving best model\n","0m 24s\n","Epoch 49/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.048905, dice: 0.064278, iou: 0.118530\n","BEGIN EVAL\n","val: criterion_loss: 0.109907, dice: 0.099115, iou: 0.175415\n","0m 24s\n","Epoch 50/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.049206, dice: 0.064441, iou: 0.118809\n","BEGIN EVAL\n","val: criterion_loss: 0.108692, dice: 0.097355, iou: 0.172677\n","0m 24s\n","Epoch 51/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.048218, dice: 0.063243, iou: 0.116764\n","BEGIN EVAL\n","val: criterion_loss: 0.107079, dice: 0.097624, iou: 0.173080\n","0m 24s\n","Epoch 52/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.047446, dice: 0.062455, iou: 0.115430\n","BEGIN EVAL\n","val: criterion_loss: 0.106702, dice: 0.094438, iou: 0.168072\n","saving best model\n","0m 24s\n","Epoch 53/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.047669, dice: 0.062315, iou: 0.115155\n","BEGIN EVAL\n","val: criterion_loss: 0.112614, dice: 0.101842, iou: 0.179943\n","0m 24s\n","Epoch 54/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.045814, dice: 0.060436, iou: 0.111967\n","BEGIN EVAL\n","val: criterion_loss: 0.115956, dice: 0.096829, iou: 0.171905\n","0m 24s\n","Epoch 55/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.044373, dice: 0.058384, iou: 0.108431\n","BEGIN EVAL\n","val: criterion_loss: 0.117461, dice: 0.097364, iou: 0.172613\n","0m 24s\n","Epoch 56/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.043844, dice: 0.057766, iou: 0.107358\n","BEGIN EVAL\n","val: criterion_loss: 0.122274, dice: 0.096930, iou: 0.171980\n","0m 24s\n","Epoch 57/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.044591, dice: 0.058486, iou: 0.108599\n","BEGIN EVAL\n","val: criterion_loss: 0.111708, dice: 0.095369, iou: 0.169419\n","0m 24s\n","Epoch 58/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.043595, dice: 0.057345, iou: 0.106642\n","BEGIN EVAL\n","val: criterion_loss: 0.116715, dice: 0.095793, iou: 0.170259\n","0m 24s\n","Epoch 59/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.042917, dice: 0.056407, iou: 0.105006\n","BEGIN EVAL\n","val: criterion_loss: 0.124779, dice: 0.099221, iou: 0.175391\n","0m 24s\n","Epoch 60/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.042394, dice: 0.055739, iou: 0.103860\n","BEGIN EVAL\n","val: criterion_loss: 0.113117, dice: 0.093035, iou: 0.165945\n","saving best model\n","0m 24s\n","Epoch 61/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.040741, dice: 0.053547, iou: 0.100017\n","BEGIN EVAL\n","val: criterion_loss: 0.118121, dice: 0.093207, iou: 0.166233\n","0m 24s\n","Epoch 62/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.040582, dice: 0.053370, iou: 0.099718\n","BEGIN EVAL\n","val: criterion_loss: 0.118263, dice: 0.094260, iou: 0.167841\n","0m 24s\n","Epoch 63/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.039601, dice: 0.052101, iou: 0.097490\n","BEGIN EVAL\n","val: criterion_loss: 0.121525, dice: 0.092808, iou: 0.165452\n","saving best model\n","0m 24s\n","Epoch 64/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.038826, dice: 0.051348, iou: 0.096177\n","BEGIN EVAL\n","val: criterion_loss: 0.125866, dice: 0.096054, iou: 0.170439\n","0m 24s\n","Epoch 65/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.038495, dice: 0.050817, iou: 0.095234\n","BEGIN EVAL\n","val: criterion_loss: 0.120033, dice: 0.090068, iou: 0.161270\n","saving best model\n","0m 24s\n","Epoch 66/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.038274, dice: 0.050287, iou: 0.094298\n","BEGIN EVAL\n","val: criterion_loss: 0.134393, dice: 0.100501, iou: 0.177448\n","0m 24s\n","Epoch 67/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.038288, dice: 0.050469, iou: 0.094623\n","BEGIN EVAL\n","val: criterion_loss: 0.121259, dice: 0.090217, iou: 0.161318\n","0m 24s\n","Epoch 68/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.036531, dice: 0.047955, iou: 0.090185\n","BEGIN EVAL\n","val: criterion_loss: 0.128483, dice: 0.094056, iou: 0.167225\n","0m 24s\n","Epoch 69/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.036502, dice: 0.048358, iou: 0.090904\n","BEGIN EVAL\n","val: criterion_loss: 0.127848, dice: 0.091547, iou: 0.163372\n","0m 24s\n","Epoch 70/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.035901, dice: 0.047324, iou: 0.089068\n","BEGIN EVAL\n","val: criterion_loss: 0.129041, dice: 0.092511, iou: 0.164856\n","0m 24s\n","Epoch 71/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.036641, dice: 0.048049, iou: 0.090340\n","BEGIN EVAL\n","val: criterion_loss: 0.123286, dice: 0.091542, iou: 0.163540\n","0m 24s\n","Epoch 72/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.035753, dice: 0.047220, iou: 0.088886\n","BEGIN EVAL\n","val: criterion_loss: 0.124484, dice: 0.089918, iou: 0.160851\n","saving best model\n","0m 24s\n","Epoch 73/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.034026, dice: 0.045017, iou: 0.084974\n","BEGIN EVAL\n","val: criterion_loss: 0.128983, dice: 0.091365, iou: 0.163069\n","0m 24s\n","Epoch 74/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.034651, dice: 0.045748, iou: 0.086273\n","BEGIN EVAL\n","val: criterion_loss: 0.133694, dice: 0.091394, iou: 0.163126\n","0m 24s\n","Epoch 75/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.034458, dice: 0.045405, iou: 0.085658\n","BEGIN EVAL\n","val: criterion_loss: 0.128801, dice: 0.089692, iou: 0.160554\n","saving best model\n","0m 24s\n","Epoch 76/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.033303, dice: 0.044033, iou: 0.083209\n","BEGIN EVAL\n","val: criterion_loss: 0.128089, dice: 0.088730, iou: 0.159021\n","saving best model\n","0m 24s\n","Epoch 77/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.034249, dice: 0.045219, iou: 0.085345\n","BEGIN EVAL\n","val: criterion_loss: 0.137443, dice: 0.091256, iou: 0.163039\n","0m 24s\n","Epoch 78/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.032841, dice: 0.043374, iou: 0.082032\n","BEGIN EVAL\n","val: criterion_loss: 0.133417, dice: 0.090355, iou: 0.161420\n","0m 24s\n","Epoch 79/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.033131, dice: 0.043880, iou: 0.082959\n","BEGIN EVAL\n","val: criterion_loss: 0.130351, dice: 0.088421, iou: 0.158386\n","saving best model\n","0m 24s\n","Epoch 80/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.032841, dice: 0.042860, iou: 0.081092\n","BEGIN EVAL\n","val: criterion_loss: 0.131352, dice: 0.089706, iou: 0.160432\n","0m 24s\n","Epoch 81/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.032424, dice: 0.042724, iou: 0.080864\n","BEGIN EVAL\n","val: criterion_loss: 0.127907, dice: 0.087706, iou: 0.157275\n","saving best model\n","0m 24s\n","Epoch 82/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.031321, dice: 0.041633, iou: 0.078910\n","BEGIN EVAL\n","val: criterion_loss: 0.135850, dice: 0.088803, iou: 0.159021\n","0m 24s\n","Epoch 83/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.030834, dice: 0.040678, iou: 0.077194\n","BEGIN EVAL\n","val: criterion_loss: 0.138721, dice: 0.090359, iou: 0.161385\n","0m 24s\n","Epoch 84/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.030417, dice: 0.040331, iou: 0.076570\n","BEGIN EVAL\n","val: criterion_loss: 0.136515, dice: 0.088487, iou: 0.158592\n","0m 24s\n","Epoch 85/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.030812, dice: 0.040754, iou: 0.077333\n","BEGIN EVAL\n","val: criterion_loss: 0.133798, dice: 0.088327, iou: 0.158253\n","0m 24s\n","Epoch 86/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.030646, dice: 0.040328, iou: 0.076561\n","BEGIN EVAL\n","val: criterion_loss: 0.138093, dice: 0.089346, iou: 0.159971\n","0m 24s\n","Epoch 87/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.030029, dice: 0.039926, iou: 0.075866\n","BEGIN EVAL\n","val: criterion_loss: 0.144733, dice: 0.089470, iou: 0.160008\n","0m 24s\n","Epoch 88/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.029877, dice: 0.039565, iou: 0.075197\n","BEGIN EVAL\n","val: criterion_loss: 0.143157, dice: 0.087819, iou: 0.157416\n","0m 24s\n","Epoch 89/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.029646, dice: 0.039060, iou: 0.074266\n","BEGIN EVAL\n","val: criterion_loss: 0.141341, dice: 0.087630, iou: 0.157255\n","saving best model\n","0m 24s\n","Epoch 90/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.029474, dice: 0.038973, iou: 0.074125\n","BEGIN EVAL\n","val: criterion_loss: 0.142308, dice: 0.089667, iou: 0.160366\n","0m 24s\n","Epoch 91/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.029628, dice: 0.039200, iou: 0.074535\n","BEGIN EVAL\n","val: criterion_loss: 0.151154, dice: 0.091060, iou: 0.162590\n","0m 24s\n","Epoch 92/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.028928, dice: 0.038354, iou: 0.072998\n","BEGIN EVAL\n","val: criterion_loss: 0.147840, dice: 0.088012, iou: 0.157747\n","0m 24s\n","Epoch 93/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.028674, dice: 0.037729, iou: 0.071855\n","BEGIN EVAL\n","val: criterion_loss: 0.146177, dice: 0.089136, iou: 0.159582\n","0m 24s\n","Epoch 94/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.028728, dice: 0.038014, iou: 0.072384\n","BEGIN EVAL\n","val: criterion_loss: 0.140148, dice: 0.088486, iou: 0.158624\n","0m 24s\n","Epoch 95/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.028531, dice: 0.037808, iou: 0.072013\n","BEGIN EVAL\n","val: criterion_loss: 0.145652, dice: 0.086691, iou: 0.155591\n","saving best model\n","0m 24s\n","Epoch 96/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.028918, dice: 0.038135, iou: 0.072611\n","BEGIN EVAL\n","val: criterion_loss: 0.152377, dice: 0.089078, iou: 0.159388\n","0m 24s\n","Epoch 97/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.027967, dice: 0.037021, iou: 0.070583\n","BEGIN EVAL\n","val: criterion_loss: 0.145540, dice: 0.088148, iou: 0.157783\n","0m 24s\n","Epoch 98/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.028247, dice: 0.037331, iou: 0.071149\n","BEGIN EVAL\n","val: criterion_loss: 0.147515, dice: 0.089058, iou: 0.159567\n","0m 24s\n","Epoch 99/99\n","----------\n","BEGIN TRAIN\n","train: criterion_loss: 0.027782, dice: 0.036743, iou: 0.070073\n","BEGIN EVAL\n","val: criterion_loss: 0.157506, dice: 0.088686, iou: 0.159048\n","0m 24s\n","Best val loss: 0.086691\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o9hW9VJGvXwb","executionInfo":{"status":"ok","timestamp":1621289498248,"user_tz":-240,"elapsed":1297,"user":{"displayName":"Vibha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEio_ZhZQPIAbRsxl7zbUbuJPoau_muMk78br7Lw=s64","userId":"04955807991990669110"}}},"source":["torch.save(model, (\"Stuff/model_wts/Unet_16\"))  "],"execution_count":5,"outputs":[]}]}